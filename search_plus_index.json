{"./":{"url":"./","title":"Introduction","keywords":"","body":"介绍 引言 本书籍,主要用来记录学习过程中遇到的问题,以及解决方式.方便以后遇到时进行查阅 导向 个人学习导向: 主要是围绕人工智能课题进行展开,会涵盖大数据,与算法模型相关的内容. 工作的导向: 也会对工作中遇到的问题进行积累,发散,记录名言警句 吾生有涯而知无涯 学海无涯乐作舟 "},"Tensorflow/":{"url":"Tensorflow/","title":"Tensorflow","keywords":"","body":"关于机器学习 从数据中学习到一些高层次,抽象的概念,这样的话对于一个新来的X他能给出一个符合实际的y 学习目标: 研究深度学习为主 了解TensorFlow为辅TensorFlow发展历史 Theano -> TensorFlow0.1 ->TensorFlow1.0 ->TensorFlow2.0TensorFlow1 调试困难 API混乱 入门困难,入门后依然困难TensorFlow2 去除了session 去除了时序控制逻辑 去除变量域的概念 将精力关注在深度学习的过程中 GPU加速 自动求导 神经网络API竞品: Caffe2 + PyTorch Chainer -> 日本 被caffe2 MXNet -> 华裔 业内使用率 TensorFlow > Keras > Pytorch > Caffe "},"Tensorflow/环境搭建.html":{"url":"Tensorflow/环境搭建.html","title":"环境搭建","keywords":"","body":"环境搭建 Anaconda,python3.7 Anaconda 集成了python3.7 安装过程中需要将环境变量勾上 不需要安装VSCode 在cmd中输入 conda list 判断是否安装成功 CUDA 必须是有NVIDIA显卡才需要安装,如果不是这种显卡,一定不能安装 TensorFlow pip install tensorflow-cpu==2.1.0 --ignore-installed 安装CPU版本 GPU版本暂不考虑 PyCharm 需要破解,建议安装2019.2以后的版本 "},"Tensorflow/线性模型.html":{"url":"Tensorflow/线性模型.html","title":"线性模型","keywords":"","body":"线性模型 自然界的y有两种类型 离散值: 向前,向后,向左,向右 连续值预测: 预测明天的天气公式: fθ:x→yf_\\theta: x \\to yf​θ​​:x→y x 输入 $f_(x)$ 预测值 y 实际值 评价: 如果$f_(x)$完全等于y,表示0误差 $f_(x)$ - y 表示误差值,后续的学习中基本都是要求这个误差值模型分类: Linear Regression线性连续值模型 Logistic Regression 非线性连续值模型 Classification 离散值模型线性模型 y=w∗x+by = w * x + by=w∗x+b 可精确求解 close form solusion 现实生活中的往往都不能精确求解 y=w∗x+b+εy = w * x + b + \\varepsilony=w∗x+b+ε 一般都预先假设$\\varepsilon$满足某种已知分布,如果是未知分布,式子没法分布 假设$\\varepsilon - N(0,1)$实例 1. 数据制造 y=1.477+0.089+εy = 1.477 + 0.089 + \\varepsilony=1.477+0.089+ε $\\varepsilon$是一个高斯噪声,服从(0,1)分布 得到100个点集2. 要求 现在需要做的事是通过给定的100个点集推导出公式3. 推导过程 将这100个点集在二维坐标系画出, [1.推测] 得到图像后推测模型,模型有可能是 [推测] 二次分布 线性分布 其他更复杂的分布这里以线性分布为例 设这个线性分布函数为: y=w∗x+b+εy = w * x + b + \\varepsilony=w∗x+b+ε 我们这里要求最满足要求的$\\varepsilon$最满足要求的值,就是求$\\varepsilon$的平方和最小的值,这样最终得到的式子与真实值得误差才是最小的 于是设置loss(误差)函数:$loss = \\sum_i(w*x_i + b - yi)^2$ 其中x,y是实际的100组数据点,w,b是要求的未知数 我们的目的转换为求解w,b的值为多少时,这个误差函数的值最小 loss=∑i(w∗xi+b−yi)2loss = \\sum_i(w*x_i + b - yi)^2loss=∑​i​​(w∗x​i​​+b−yi)​2​​ 求解这个函数的极小值需要用到Gradient Descent(最陡下降法,梯度下降法)方法 梯度下降法: $x_2 = x_1 - lr * \\frac{dy}{dx}$. 其中$x_1$是当前的点,$x_2$是通过计算后得到更满足要求的下一个点. 如果是求极小值,lr是负数,如果是求极大值,lr是正数,这样才能保证下一个点在极值点附近徘徊 lr是衰减因子,越小,需要计算的次数越多,结果越精确 梯度下降法只能找到极小值,不能找到最小值.所以使用梯度下降算法时需要明确一个合适的区间 $w_2 = w_1 + lr * \\frac {\\partial loss}{\\partial w}$ $b_2 = b_1 + lr * \\frac {\\partial loss}{\\partial b}$ 得到: $w_2 * x + b_2 -y$的值,求平方,对多个(x,y)求和 $\\frac {\\partial loss}{\\partial w} = 2 \\sum_i(wx_i + b - y_i)x_i$ $\\frac {\\partial loss}{\\partial b} = 2 * \\sum_i(wx_i + b - y_i)$ NumPy实战 import tensorflow as tf import os import numpy as np os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # y = wx + b def compute_error_for_line_given_points(b, w, points): totalError = 0 for i in range(0, len(points)): x = points[i, 0] y = points[i, 1] # compute mean-squared-error totalError += (y - (w * x + b)) ** 2 # average loss for each point return totalError / float(len(points)) def step_gradient(b_current, w_current, points, learning_rate): b_gradient = 0 w_gradient = 0 N = float(len(points)) for i in range(0, len(points)): x = points[i, 0] y = points[i, 1] # grade_b = 2(wx + b - y) b_gradient += (2 / N) * ((w_current * x + b_current) - y) # grade_w = 2(wx + b - y)*x w_gradient += (2 / N) * x * ((w_current * x + b_current) - y) # update w new_b = b_current - (learning_rate * b_gradient) new_w = w_current - (learning_rate * w_gradient) return [new_b, new_w] def gradient_descent_runner(points, starting_b, starting_w, learning_rate, num_iterations): b = starting_b w = starting_w # update for several times for i in range(num_iterations): b, w = step_gradient(b, w, np.array(points), learning_rate) return [b, w] def run(): points = np.genfromtxt(\"data.csv\", delimiter=\",\") learning_rate = 0.0001 initial_b = 0 # initial y-intercept guess initial_w = 0 # initial slope guess num_iterations = 200 print(\"Starting gradient descent at b = {0}, w = {1}, error = {2}\" .format(initial_b, initial_w, compute_error_for_line_given_points(initial_b, initial_w, points))) print(\"Running...\") [b, w] = gradient_descent_runner(points, initial_b, initial_w, learning_rate, num_iterations) print(\"After {0} iterations b = {1}, w = {2}, error = {3}\" .format(num_iterations, b, w, compute_error_for_line_given_points(b, w, points))) if __name__ == '__main__': run() 结果: 实际值 b = 1.477 w = 0.089 After 200 iterations b = 0.04107767129742342, w = 1.4786847362774305, error = 112.64345202278727 After 1000 iterations b = 0.08893651993741346, w = 1.4777440851894448, error = 112.61481011613473 "},"Tensorflow/手写数字问题.html":{"url":"Tensorflow/手写数字问题.html","title":"手写数字问题","keywords":"","body":"前置知识基础 矩阵知识 见预备数学知识目录 欧式距离 欧几里得度量,又称欧式距离.是一个通常采用的距离定义,指在m维空间中两个点之间的真实距离,或者向量的自然长度.在二维,三维空间中欧式距离就是两点之间的实际距离. d(x,y)=(x1−y1)2+(x2−y2)2+...+(xn−yn)2d(x,y) = \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + ... + (x_n-y_n)^2}d(x,y)=√​(x​1​​−y​1​​)​2​​+(x​2​​−y​2​​)​2​​+...+(x​n​​−y​n​​)​2​​​​​ on hot编码 仅允许单一位元数字为1,其他数字都为0.在机器学习中存在one-hot向量的概念.任意维度的向量中,仅有一个维度为1,其他维度都为0. 手写数字问题分析 目标 给定任意一个手写数字图片能够识别写的数字是多少 数据来源以及处理 来自YanLeKun(深度学习三驾马车之一)收集的70K数据.其中60K数据用来训练,10k数据用来测试 例如一张写了8的图片,以及转义后的数据图片 关于图片信息的转换 这样,就将一张图片数据转换为一个28行28列的二维数组数据.设定每个格子的值在0-256(8位一个字节二进制),0代表全白,256代表全黑. 所以我们就将一张图片数据转换为一个[28,28,1]的数据.1,代表是黑白. 如果我们拿到的是彩色图片,就需要用[28,28,3]来代替了.3代表RGB三种颜色通道 关于数据打平 对于每一张图片,我们拿到的是一个二维,甚至是三维的数据.其实这种数据是可以打平为一维的向量,计算起来会方便很多,但是会也会损失上与下的空间信息. 打平的方式是这样的:我们将第二行的数值搬到第一行的末尾,第三行..类似.最终会得到一个[28*28,1]的数据. 关于分类问题的输出 输入就是我们上文的数据,[28*28,1],输出是我们会将需要分类的每一个类别赋值一个数值信息.我们总共有0-9,共计10个数,相当于我们的输出是[10]. 但是数值之间其实是有关系的,如 0要比1小 1.2要更接近于1,远离2 实际我们要分类的类别是没有大小关系的以及中间值问题的. 1.2这种解释是并不属于我们10种问题中的任何一个类别 所以我们要定义一种规则来避免上述两种问题 单纯的给每个类别编号,0~9,每个类别之间的关系并不带有数字的连续性关系 引入概率的方式,我们给出判定为某个类别的概率为多少,每个图片进行判定的时候,每个分类值都给一个概率.10个分类的概率和为1.然后认为概率最大的那个分类即我们推断分类.(one-hot) Regression VS Classsification $y = W * X + b$ 其中y是连续的$y \\in R^d$ $out = X@W + b$ $out = [0.1, 0.8, 0.002, 0.008]$ @是矩阵相乘的意思 X: [1, 784] W: [784,10] 这样矩阵W才能跟矩阵X相乘 b: [10] 运算过程: [1, 784]@[784, 10] + [10] = [1, 10]问题 这个矩阵运算实际上还是一个线性的计算 图片的识别是很复杂的,一个线性模型是很难进行识别的解决方式 引入一个简单的非线性因子,ReLU函数$out = f(x@w) + b$ 引入火车模型.火车的特色是一节节车厢.每节车厢相当于一次处理,每次处理后的结果作为下次处理的入参.这里引入三道工序 $h_1 = relu(X @ W_1 + b_1)$ $h_2 = relu(X @ W_2 + b_2)$ $out = relu(X @ W_3 + b_3)$实际降维计算过程 X = [v1, v2, ..., V784] X: [1, 784]h1 = relu(X@W1 + b1) W1: [784, 512] x1: [1, 512]h2 = relu(h1@W2 + b2) W2: [512, 256] b2: [256]out = relu(h2@W3) + b3 W3: [256, 10] b3: [10] loss函数(求欧式距离) $out = relu{relu{relu[x@W_1 + b_1]@W_2 + b_2}@W_3 + b_3}$ $pred = argmax(out)$ $loss = MSE(out, lable)$ MSE就是求欧式距离 lable是真实值 求loss的最小值过程(minimize loss)就是优化参数[w1,b1,w2,b2,w3,b3]的过程 得到最优[w1,b1,w2,b2,w3,b3]后,带入out式子,用来预计新的图片对应的手写数字 如果我们不是做三道工序,而是30道工序,那么就是deep learning了 实际编码 import os import tensorflow as tf from tensorflow import keras from tensorflow.keras import datasets, layers, optimizers os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # 在线加载mnist数据 # 加载的数据是numpy的格式 # x是数据,y是实际结果 (x, y), (x_val, y_val) = datasets.mnist.load_data() # 将numpy格式数据转换为tensor格式的数据 x = tf.convert_to_tensor(x, dtype=tf.float32) / 255. y = tf.convert_to_tensor(y, dtype=tf.int32) y = tf.one_hot(y, depth=10) print('datasets:', x.shape, y.shape) # 将给定数据集进行分片处理 train_dataset = tf.data.Dataset.from_tensor_slices((x, y)) # 设定分片批次大小 train_dataset = train_dataset.batch(200) # 准备阶段,准备网络结构 这里是设定了一个3层的网络结构 784 -> 512 512 -> 256 256 -> 10 model = keras.Sequential([ layers.Dense(512, activation='relu'), layers.Dense(256, activation='relu'), layers.Dense(10)]) # 准备优化器 构造一个随机的梯度下降算法,并初始化一个给定的偏移率 optimizer = optimizers.SGD(learning_rate=0.001) def train_epoch(epoch): # print(\"=========================================\") # step4. loop # train_dataset 已在上文设为每次训练使用200个图片数据 for step, (x, y) in enumerate(train_dataset): with tf.GradientTape() as tape: # [b, 28, 28] -> [b, 784] 将二维数据打平到一维 x = tf.reshape(x, (-1, 28 * 28)) # step 1. compute output 进行深度计算 # [b, 784] -> [b, 10] out = model(x) # step2. compute loss . loss = tf.reduce_sum(tf.square(out - y)) / x.shape[0] # step3, 自动求导 optimize and update w1, w2, w3, b1, b2, b3 grads = tape.gradient(loss, model.trainable_variables) # w_2 = w_1 - lr * grade optimizer.apply_gradients(zip(grads, model.trainable_variables)) if step % 99 == 0: print(\"epoch:\", epoch, step, 'loss:', loss.numpy) def train(): # 将程序使用同一个数据集训练30次 print(\"=====start=====\") for epoch in range(30): train_epoch(epoch) print(\"=======================train epoch = {0}=======================\", epoch) print(\"=====end=====\") if __name__ == '__main__': train() 运行结果 第一次训练: epoch: 0 0 loss: > epoch: 0 99 loss: > epoch: 0 198 loss: > epoch: 0 297 loss: > 第30次训练: epoch: 29 0 loss: > epoch: 29 99 loss: > epoch: 29 198 loss: > epoch: 29 297 loss: > 由日志可知,经过30次训练后,我们的误差函数的结果由最开始1.9502934变为最后的0.20265716,基本来说下降了10倍 要注意的是,进行深度学习的训练对硬件要求是很高的,我R7的CPU基本用了80% "},"Python/":{"url":"Python/","title":"Python","keywords":"","body":"Python 我之前有在菜鸟教程通读一遍python基础知识,这里不会再系统的去学习python的用法,而是每次遇到不懂得语法,属性或函数会记录下来.当然,如果某些知识点收集的时候发现篇幅过长,我还是会将他们单独放到一个专门的文件里面,不占用太多的篇幅 1. data.shape 查看矩阵或者数组的维数2. with...as ``` class test(): def init(self): self.text = \"hello\" def enter(self): self.text += \" world\" return self #这句必须要有，不然with ... as 时，as后面的变量没法被赋值 def exit(self, arg1, arg2, arg3): #一共四个参数，后面四个参数是好像是关于异常信息的，没研究过，先这样写着 self.text += \"!\" def Print(self): print self.text try: with test() as f: #在with ... as的作用域内，进入会执行test()的enter()函数，出作用域执行exit()函数 f.Print() raise StopIteration except StopIteration: f.Print() 运行结果: hello world hello world! ``` 在with...as的作用域内,进入会先执行test()的enter()函数,出去会执行exit() 如果在作用域内发生异常,出去的时候,enter()函数仍然会执行 f的作用域并不局限于with ... as内 test类中函数的执行顺序是 init() -->enter() --> f.Print() --> exit "},"Python/python容器类型.html":{"url":"Python/python容器类型.html","title":"python容器类型","keywords":"","body":"python容器类型 列表,刑如[a,b,c,d] 常见操作: print(list) print(list[0]) print(list[1:3]) 输出从第1(从0开始算)个元素开始到底3个元素(不包含)结束 print(list[2:]) 输出从第2个元素开始的所有元素 print(list * 2) 输出两次列表 print(list1 + list2) 连接列表 注意: list内置了很多方法,包括append,pop等 list写在方括号中间,元素用逗号隔开 list可以被索引和切片 list可以使用+操作符进行拼接 list中的元素可以被改变 -1是最后一个元素的索引 元组,刑如 (a,b,c) 常见操作 print(tuple) print(tuple[0]) print(tuple[1:3]) 输出元素从第1(从0开始算)个元素到底3个元素(不包含)结束 print(tuple[2:]) 输出从第2(从0开始算)个元素开始的所有元素 print(tuple * 2) 输出两次元组 print(tuple + tuple2) 连接两个元组 注意 元组元素是不能变的,但是它可以包含可变对象(相当于java容器中元素的的引用不能变,但是引用所指向的内容是可以) 索引,切片类似列表 特殊元组的定义: 空元组 tup1 = () 一个元素的元组 tup2 = (1,) 集合 刑如: {a, b, c} 常见操作 a = set('123456') 初始化一个集合 if '1' in a 判断元素是否在集合内 print (a) print(a - b) 求两个结合的差集 print (a|b) 求两个集合的并集 print (a & b) 求两个集合的交集 print (a ^ b) 求a,b不同时存在的元素 注意 集合中的数据不能重复 {}或者set()都能初始化集合,但是如果初始化的集合没有内容,只用用set() 字典 刑如: {\"a\":1,\"b\":2} 常见操作 print(dict('a') 输出key为a的值 print(dict[2]) 输出key为2的值 print(dict) 输出整个字典 print(dict.keys()) 输出key的所有key print(dict.values) 输出key的所有value 注意 字典就类似java里的map 字典的key必定不可变,且不能重复 创建空字典用{} "},"工具/":{"url":"工具/","title":"工具","keywords":"","body":"工具 主要用来记录常用工具的一些使用指令 "},"工具/git.html":{"url":"工具/git.html","title":"GIT","keywords":"","body":"GIT 第一次提交 git init //本地初始化 git add README.md //添加一个文件 git add . //将添加的文件添加到git管理 git config --global user.email \"287329409@qq.com\" //设置全局邮箱 git config --global user.name \"Chen Hao\" //设置全局用户名 git commit -m \"first commit\" //提交代码 git remote add origin https://github.com/wilnd/ChenHao.github.io.git //将本地代码跟远端代码关联起来 git push -u origin master //将本地代码推到远端 常用指令 git fetch --all 拿到远端所有分支名 git pull --all 拿到远端所有分支内容 "},"工具/gitbook.html":{"url":"工具/gitbook.html","title":"GitBook","keywords":"","body":"GitBook 初次安装 npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install gitbook-cli -g gitbook -V常用指令 gitbook init gitbook build gitbook serve编译上传shell脚本 #! /bin/bash cd doc # gitbook install # install the plugins and build the static site gitbook build cd .. # checkout to the gh-pages branch git checkout gh-pages # pull the latest updates git pull origin gh-pages if [[ \"$?\" != \"0\" ]]; then exit 1 fi # copy the static site files into the current directory. \\cp -Rf doc/_book/* . # remove 'node_modules' and '_book' directory # git clean -fx gitbook/node_modules # git clean -fx gitbook/_book rm -rf doc/_book/ # remove website css files, except last one ccount=`ls website-* | wc -w` if [[ \"$ccount\" > 1 ]];then allcss=($(ls website-*)) c=0 for css in \"${allcss[@]}\"; do let \"c=c+1\" if [[ $c -ge $ccount ]]; then break; fi rm -f $css done fi # add all files git add --all # commit git commit -a -m \"Update docs\" # push to the origin git push origin gh-pages # checkout to the master branch git checkout master "},"工具/VPN.html":{"url":"工具/VPN.html","title":"VPN","keywords":"","body":"VPN 使用秋水逸冰的脚本搭建VPN root用户登录 wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh chmod +x shadowsocksR.sh ./shadowsocksR.sh 2>&1 | tee shadowsocksR.log常用命令 启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 状态：/etc/init.d/shadowsocks status 配置文件路径：/etc/shadowsocks.json 日志文件路径：/var/log/shadowsocks.log 代码安装目录：/usr/local/shadowsocks "},"预备数学知识/":{"url":"预备数学知识/","title":"预备数学知识","keywords":"","body":"预备数学知识 我个人在大学阶段,数学并没有好好学,在学习深度学习这个课题的的过程中经常性的会遇到一些数学问题,这个时候就需要查阅相关资料进行补充学习.现将查阅整理后的资料整理到如下这个目录中 "},"预备数学知识/概念.html":{"url":"预备数学知识/概念.html","title":"概念","keywords":"","body":"概念 欧式距离 欧式距离又称欧几里得度量,是一个通常采用的距离公式.指在m维空间中两个点之间的真实距离(为正数),或者向量的自然长度.在TensorFlow中常常用来计算loss函数. 二维空间公式 $\\rho = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$, $\\rho$为($x_2, y_2$)与点($x_1, y_1$)之间的欧式距离 n维空间 $d(x,y) = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + (x_3 - y_3)^2 + ... + (x_n - y_n)^2}$ "},"预备数学知识/矩阵.html":{"url":"预备数学知识/矩阵.html","title":"矩阵","keywords":"","body":"矩阵运算知识 矩阵线性运算 矩阵的加法 只有当两个矩阵是同型矩阵时才能进行加法运算 两个矩阵相加,那么矩阵中每个对应元素都相加 数与矩阵相乘 矩阵跟实数相乘,矩阵中每个元素都跟实数相乘# 矩阵与矩阵相乘 只有第一个矩阵的列数等于第二个矩阵的行数时才能相乘 矩阵乘法不满足交换律 矩阵乘法满足结合律,分配律 m(AB) = (mA)B = A(mB) 其中m为实数 如果A是n阶方阵, 矩阵的转置 矩阵的行列互换,得到的新矩阵叫做矩阵的转置 A两次转置,得到A本身 (A+B)的转置等于A转+B转 (mA)的转置等于mA的转置 (AB)的转置等于A转*B转 方阵行列式 由n阶方阵A的元素构成的行列式叫做方阵A的行列式叫做|A|或detA A的行列式等于A转置的行列式 |mA|=m^n|A| |AB|=|A||B|=|B||A|=|BA|余子式 余子式:在n阶行列式中,将元素a_oe i所在的第o行第i列划掉后,留下来的n-1阶行列式,叫做元素a_oe i的余子式,基座M_oe 代数余子式:将余子式M_oe乘以-1deo+e次幂,基座A_oe,叫做a_oe的代数余子式 伴随矩阵:行列式|A|的各个元素的余子式A_ij所构成的矩阵称为矩阵A的伴随矩阵A* 性质: AA = AA = |A|E共轭矩阵 "},"问题/":{"url":"问题/","title":"问题","keywords":"","body":"问题 "},"问题/运维问题.html":{"url":"问题/运维问题.html","title":"运维问题","keywords":"","body":"运维问题 pip下载过慢 需要配置国内镜像 Linux 修改 ~/.pip/pip.conf (没有就创建一个文件夹及文件。文件夹要加“.”，表示是隐藏文件夹) windows下，直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，新建文件pip.ini[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host=mirrors.aliyun.com You are using pip version 10.0.1, however version 20.1 is available python -m pip install --upgrade pip twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed. pip install PyHamcrest google-auth 1.14.2 has requirement setuptools>=40.3.0, but you'll have setuptools 40.2.0 which is incompatible. pip uninstall setuptools pip install --ignore-installed setuptools==40.3.0 tensorboard 2.1.1 has requirement setuptools>=41.0.0, but you'll have setuptools 40.2.0 which is incompatible pip install tensorflow-cpu --ignore-installed 告警Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 只限于CPU会报这个错.除了通常的算术和逻辑，现代CPU提供了许多低级指令，称为扩展，例如， SSE2，SSE4，AVX等 在代码中加入如下代码，忽略警告import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "},"日记/":{"url":"日记/","title":"日记","keywords":"","body":"每日一记 不积跬步无以至千里,不积小流无以成江海 "},"日记/2020.html":{"url":"日记/2020.html","title":"2020","keywords":"","body":"2020 5.06 搭建个人微信公众号:\"陈半仙翁的修行笔记\",公众号主要用来记录大数据/人工智能模块的学习 5.07 搭建VPN/搭建gitbook 5.08 搭建TensorFlow本地运行需要的环境 5.09 整理第一个章节成文档:线性模型 5.10 学习第二个章节:基于tensroflow的分类算法 5.11 装了一个唱歌的声卡 5.12 将第二个章节的内容在本地运行 5.13 将第一个章节通过微信公众号的形式进行发布,并整理第二个章节的内容为文档 "}}